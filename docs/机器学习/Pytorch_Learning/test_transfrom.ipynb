{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08428101-b497-4c0d-a9f0-2510cc39098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8ce9ab-2d86-44a6-a3e7-2624174ff3bb",
   "metadata": {},
   "source": [
    "## ğŸ–¼ï¸ TorchVision ä»‹ç»\n",
    "\n",
    "**TorchVision** æ˜¯ PyTorch å®˜æ–¹æ”¯æŒçš„ã€ä¸“é—¨ç”¨äº**è®¡ç®—æœºè§†è§‰ (Computer Vision)** ä»»åŠ¡çš„åº“ã€‚å®ƒæ˜¯ PyTorch ç”Ÿæ€ç³»ç»Ÿä¸­ä¸å¯æˆ–ç¼ºçš„ä¸€éƒ¨åˆ†ï¼Œæå¤§åœ°ç®€åŒ–äº†è®¡ç®—æœºè§†è§‰ç ”ç©¶å’Œåº”ç”¨çš„å¼€å‘è¿‡ç¨‹ã€‚\n",
    "\n",
    "TorchVision ä¸»è¦ç”±ä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—æ„æˆï¼Œå…±åŒä¸ºè§†è§‰ä»»åŠ¡æä¾›é«˜æ•ˆçš„æ”¯æŒï¼š\n",
    "\n",
    "---\n",
    "\n",
    "### 1. `torchvision.datasets` (æ•°æ®é›†)\n",
    "\n",
    "è¿™ä¸ªæ¨¡å—æä¾›äº†å¤§é‡**é¢„å…ˆå‡†å¤‡å¥½çš„ã€å¸¸ç”¨çš„å…¬å…±æ•°æ®é›†**ï¼Œä½ å¯ä»¥ç›´æ¥ä¸‹è½½å’Œä½¿ç”¨ï¼Œæ— éœ€è‡ªå·±ç¼–å†™å¤æ‚çš„æ•°æ®åŠ è½½ä»£ç ã€‚\n",
    "\n",
    "* **æ ¸å¿ƒåŠŸèƒ½:** æ–¹ä¾¿åœ°åŠ è½½æ ‡å‡†æ•°æ®é›†è¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•ã€‚\n",
    "* **å¸¸è§æ•°æ®é›†ç¤ºä¾‹:**\n",
    "    * **Image Classification (å›¾åƒåˆ†ç±»):** `MNIST`, `CIFAR10`, `ImageNet` (éœ€è¦æ‰‹åŠ¨ä¸‹è½½å’Œç»„ç»‡æ–‡ä»¶)ã€‚\n",
    "    * **Object Detection (ç›®æ ‡æ£€æµ‹):** `CocoDetection`, `Kitti`.\n",
    "    * **Semantic Segmentation (è¯­ä¹‰åˆ†å‰²):** `VOCSegmentation`.\n",
    "\n",
    "### 2. `torchvision.models` (é¢„è®­ç»ƒæ¨¡å‹)\n",
    "\n",
    "è¿™ä¸ªæ¨¡å—æä¾›äº†å¤§é‡**é¢„è®­ç»ƒçš„ã€é«˜æ€§èƒ½çš„ç¥ç»ç½‘ç»œæ¨¡å‹**ã€‚è¿™äº›æ¨¡å‹é€šå¸¸åœ¨å¤§å‹æ•°æ®é›†ï¼ˆå¦‚ ImageNetï¼‰ä¸Šè®­ç»ƒè¿‡ï¼Œå¯ä»¥ç›´æ¥ç”¨äºç‰¹å¾æå–æˆ–ä½œä¸º**è¿ç§»å­¦ä¹  (Transfer Learning)** çš„èµ·ç‚¹ã€‚\n",
    "\n",
    "* **æ ¸å¿ƒåŠŸèƒ½:** å¿«é€Ÿè·å–å’Œä½¿ç”¨ç»è¿‡éªŒè¯çš„ç»å…¸æˆ–å…ˆè¿›æ¨¡å‹ã€‚\n",
    "* **å¸¸è§æ¨¡å‹æ¶æ„ç¤ºä¾‹:**\n",
    "    * **Classification (åˆ†ç±»):** `ResNet` (å¦‚ `resnet50`), `VGG`, `MobileNet`, `EfficientNet`.\n",
    "    * **Object Detection (ç›®æ ‡æ£€æµ‹):** `Faster R-CNN`, `SSD`, `RetinaNet`.\n",
    "    * **Segmentation (åˆ†å‰²):** `FCN`, `DeepLabV3`.\n",
    "\n",
    "### 3. `torchvision.transforms` (æ•°æ®å˜æ¢/é¢„å¤„ç†)\n",
    "\n",
    "è¿™ä¸ªæ¨¡å—æä¾›äº†å„ç§**å›¾åƒé¢„å¤„ç†å’Œæ•°æ®å¢å¼º (Data Augmentation)** æ“ä½œã€‚åœ¨å°†åŸå§‹å›¾åƒè¾“å…¥åˆ°ç¥ç»ç½‘ç»œä¹‹å‰ï¼Œé€šå¸¸éœ€è¦è¿›è¡Œè¿™äº›å¤„ç†ã€‚\n",
    "\n",
    "* **æ ¸å¿ƒåŠŸèƒ½:** å¯¹ PIL Image æˆ– Tensor è¿›è¡Œå„ç§æ“ä½œï¼Œå¦‚å°ºå¯¸è°ƒæ•´ã€è£å‰ªã€å½’ä¸€åŒ–ç­‰ã€‚\n",
    "* **å¸¸è§æ“ä½œç¤ºä¾‹:**\n",
    "    * `ToTensor()`: å°† PIL Image æˆ– NumPy æ•°ç»„è½¬æ¢æˆ PyTorch Tensorã€‚\n",
    "    * `Normalize()`: å¯¹ Tensor è¿›è¡Œæ ‡å‡†åŒ–å¤„ç† (å‡å»å‡å€¼ï¼Œé™¤ä»¥æ ‡å‡†å·®)ã€‚\n",
    "    * `Resize()`: æ”¹å˜å›¾åƒå°ºå¯¸ã€‚\n",
    "    * `RandomCrop()`: éšæœºè£å‰ªï¼Œç”¨äºæ•°æ®å¢å¼ºã€‚\n",
    "    * `Compose()`: å°†å¤šä¸ªå˜æ¢æ“ä½œä¸²è”èµ·æ¥ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### æ€»ç»“\n",
    "\n",
    "TorchVision æ˜¯ PyTorch ç”¨æˆ·è¿›è¡Œè®¡ç®—æœºè§†è§‰é¡¹ç›®æ—¶çš„**æ ‡é…å·¥å…·ç®±**ï¼Œå®ƒé€šè¿‡æä¾›å³æ’å³ç”¨çš„æ•°æ®é›†ã€æ¨¡å‹å’Œé¢„å¤„ç†å·¥å…·ï¼Œå¸®åŠ©å¼€å‘è€…ï¼š\n",
    "\n",
    "1.  **å¿«é€Ÿå¯åŠ¨é¡¹ç›®:** åˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹å’Œæ ‡å‡†æ•°æ®é›†å¿«é€Ÿæ„å»ºåŸå‹ã€‚\n",
    "2.  **ä¿è¯æ•°æ®å¤„ç†ä¸€è‡´æ€§:** ä½¿ç”¨ç»Ÿä¸€çš„ `transforms` API è¿›è¡Œæ•°æ®é¢„å¤„ç†ã€‚\n",
    "3.  **èŠ‚çœèµ„æº:** é¿å…é‡å¤å®ç°å¸¸è§æ¨¡å‹çš„ä»£ç ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34005954-5c17-4805-b7e8-bc00f0265b60",
   "metadata": {},
   "source": [
    "# transform\n",
    "##  `torchvision.transforms` ä»‹ç»\n",
    "\n",
    "`torchvision.transforms` æ˜¯ **TorchVision** åº“ä¸­ä¸“é—¨ç”¨äºå›¾åƒ**é¢„å¤„ç† (Preprocessing)** å’Œ**æ•°æ®å¢å¼º (Data Augmentation)** çš„æ ¸å¿ƒæ¨¡å—ã€‚\n",
    "\n",
    "åœ¨å°†åŸå§‹å›¾åƒæ•°æ®é€å…¥ç¥ç»ç½‘ç»œä¹‹å‰ï¼Œæˆ‘ä»¬å‡ ä¹æ€»æ˜¯éœ€è¦è¿›è¡Œä¸€ç³»åˆ—çš„è½¬æ¢æ“ä½œï¼Œè€Œ `transforms` æ¨¡å—å°±æ˜¯ä¸ºæ­¤è®¾è®¡çš„ã€‚\n",
    "\n",
    "### æ ¸å¿ƒç›®çš„\n",
    "\n",
    "1.  **ç»Ÿä¸€è¾“å…¥æ ¼å¼:** å°†ä¸åŒæ ¼å¼çš„è¾“å…¥ï¼ˆå¦‚ PIL Image, NumPy Arrayï¼‰è½¬æ¢ä¸º PyTorch æ¨¡å‹æ‰€éœ€çš„ `Tensor` æ ¼å¼ã€‚\n",
    "2.  **æ ‡å‡†åŒ–:** å¯¹åƒç´ å€¼è¿›è¡Œå½’ä¸€åŒ–ï¼Œä½¿å…¶å‡å€¼æ¥è¿‘ 0ã€æ ‡å‡†å·®æ¥è¿‘ 1ï¼Œæœ‰åŠ©äºæ¨¡å‹è®­ç»ƒæ”¶æ•›ã€‚\n",
    "3.  **æ•°æ®å¢å¼º:** é€šè¿‡éšæœºå˜æ¢ï¼ˆå¦‚è£å‰ªã€ç¿»è½¬ã€æ—‹è½¬ï¼‰ï¼Œå¢åŠ è®­ç»ƒæ•°æ®çš„å¤šæ ·æ€§ï¼Œä»è€Œæé«˜æ¨¡å‹çš„**æ³›åŒ–èƒ½åŠ›**ï¼Œå‡å°‘è¿‡æ‹Ÿåˆã€‚\n",
    "\n",
    "### å¸¸è§æ“ä½œåˆ†ç±»åŠç¤ºä¾‹\n",
    "\n",
    "#### 1\\. åŸºç¡€è½¬æ¢ (Normalization & Format)\n",
    "\n",
    "| è½¬æ¢æ–¹æ³• | ä½œç”¨ | ç›®çš„ |\n",
    "| :--- | :--- | :--- |\n",
    "| `ToTensor()` | å°† PIL Image æˆ– NumPy `ndarray` è½¬æ¢ä¸º `FloatTensor`ã€‚ | **å¿…é¡»çš„æ“ä½œ**ï¼Œå°†æ•°æ®è½¬æ¢ä¸ºæ¨¡å‹èƒ½å¤„ç†çš„ PyTorch å¼ é‡ã€‚ |\n",
    "| `Normalize(mean, std)` | æ ¹æ®ç»™å®šçš„å‡å€¼å’Œæ ‡å‡†å·®å¯¹ Tensor è¿›è¡Œæ ‡å‡†åŒ–ã€‚ | å°†åƒç´ å€¼ç¼©æ”¾åˆ°ä¸€ä¸ªåˆé€‚çš„èŒƒå›´ï¼ŒåŠ é€Ÿæ¨¡å‹æ”¶æ•›ã€‚ |\n",
    "| `Resize(size)` | å°†è¾“å…¥å›¾åƒè°ƒæ•´åˆ°æŒ‡å®šçš„å°ºå¯¸ã€‚ | ç¡®ä¿æ‰€æœ‰è¾“å…¥å›¾åƒå°ºå¯¸ç»Ÿä¸€ã€‚ |\n",
    "\n",
    "#### 2\\. æ•°æ®å¢å¼º (Augmentation)\n",
    "\n",
    "| è½¬æ¢æ–¹æ³• | ä½œç”¨ | ç›®çš„ |\n",
    "| :--- | :--- | :--- |\n",
    "| `RandomCrop(size)` | ä»å›¾åƒä¸­éšæœºè£å‰ªä¸€å—æŒ‡å®šå¤§å°çš„åŒºåŸŸã€‚ | å¢åŠ è®­ç»ƒæ ·æœ¬çš„å¤šæ ·æ€§å’Œå¹³ç§»ä¸å˜æ€§ã€‚ |\n",
    "| `RandomHorizontalFlip(p=0.5)` | ä»¥ç»™å®šçš„æ¦‚ç‡æ°´å¹³éšæœºç¿»è½¬å›¾åƒã€‚ | å¢åŠ æ•°æ®çš„å¯¹ç§°æ€§ã€‚ |\n",
    "| `RandomRotation(degrees)` | éšæœºæ—‹è½¬å›¾åƒä¸€ä¸ªè§’åº¦èŒƒå›´ã€‚ | å¢åŠ æ¨¡å‹çš„æ—‹è½¬ä¸å˜æ€§ã€‚ |\n",
    "| `ColorJitter(brightness=0.2, ...)`| éšæœºæ”¹å˜å›¾åƒçš„äº®åº¦ã€å¯¹æ¯”åº¦ã€é¥±å’Œåº¦å’Œè‰²è°ƒã€‚ | ä½¿æ¨¡å‹å¯¹å…‰ç…§å˜åŒ–æ›´å…·é²æ£’æ€§ã€‚ |\n",
    "\n",
    "#### 3\\. ç»„åˆæ“ä½œ\n",
    "\n",
    "| è½¬æ¢æ–¹æ³• | ä½œç”¨ | ç›®çš„ |\n",
    "| :--- | :--- | :--- |\n",
    "| `Compose([...])` | **å°†å¤šä¸ªè½¬æ¢æ“ä½œæŒ‰é¡ºåºä¸²è”èµ·æ¥ã€‚** | è¿™æ˜¯æœ€å¸¸ç”¨çš„æ–¹æ³•ï¼Œç”¨äºå®šä¹‰ä¸€ä¸ªå®Œæ•´çš„é¢„å¤„ç†æµç¨‹ã€‚ |\n",
    "\n",
    "### `Compose` ç¤ºä¾‹ (æ ‡å‡†çš„é¢„å¤„ç†æµç¨‹)\n",
    "\n",
    "åœ¨å®é™…åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ä½¿ç”¨ `transforms.Compose` å°†å¤šä¸ªæ“ä½œç»„åˆæˆä¸€ä¸ªæµç¨‹ï¼š\n",
    "\n",
    "```python\n",
    "from torchvision import transforms\n",
    "\n",
    "# å®šä¹‰ä¸€ä¸ªæ ‡å‡†çš„é¢„å¤„ç†æµç¨‹\n",
    "transform = transforms.Compose([\n",
    "    # 1. è°ƒæ•´å›¾åƒå°ºå¯¸åˆ° 256x256\n",
    "    transforms.Resize(256),  \n",
    "    \n",
    "    # 2. ä» 256x256 çš„å›¾åƒä¸­éšæœºè£å‰ª 224x224 çš„åŒºåŸŸ (ç”¨äºæ•°æ®å¢å¼º)\n",
    "    transforms.RandomCrop(224), \n",
    "    \n",
    "    # 3. ä»¥ 50% çš„æ¦‚ç‡æ°´å¹³ç¿»è½¬å›¾åƒ (ç”¨äºæ•°æ®å¢å¼º)\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    \n",
    "    # 4. å¿…é¡»æ“ä½œï¼šå°†å›¾åƒè½¬æ¢ä¸º PyTorch Tensor\n",
    "    transforms.ToTensor(),      \n",
    "    \n",
    "    # 5. å¿…é¡»æ“ä½œï¼šè¿›è¡Œæ ‡å‡†åŒ– (ä½¿ç”¨ ImageNet çš„å‡å€¼å’Œæ ‡å‡†å·®ä½œä¸ºç¤ºä¾‹)\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "# å‡è®¾ image æ˜¯ä¸€ä¸ª PIL å›¾åƒå¯¹è±¡\n",
    "# processed_tensor = transform(image)\n",
    "```\n",
    "\n",
    "### æ€»ç»“\n",
    "\n",
    "`torchvision.transforms` æ¨¡å—é€šè¿‡æä¾›ä¸€ä¸ªæ¸…æ™°ã€çµæ´»çš„ APIï¼Œä½¿å¾—æ·±åº¦å­¦ä¹ å·¥ç¨‹å¸ˆå¯ä»¥æ–¹ä¾¿åœ°ï¼š\n",
    "\n",
    "  * **æ„å»º**æ¨¡å‹æ‰€éœ€çš„è¾“å…¥å¼ é‡ã€‚\n",
    "  * **åº”ç”¨**å„ç§æ•°æ®å¢å¼ºæŠ€æœ¯æ¥æ”¹è¿›æ¨¡å‹æ€§èƒ½å’Œé²æ£’æ€§ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b9f911e-019d-4e75-8f88-902956e9488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è½¬æ¢å›¾ç‰‡\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d0dfc1c-4864-4a64-bc3d-5795ab8fa36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n"
     ]
    }
   ],
   "source": [
    "img_path = 'dataset/train/ants/0013035.jpg'\n",
    "img = Image.open(img_path)\n",
    "print(type(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f2c800b-7cdd-4351-88cd-4d5971fcaf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "tensor_trans = transforms.ToTensor() #å®ä¾‹åŒ–ç±»\n",
    "img_tensor = tensor_trans(img) #è°ƒç”¨ç±»(å°±æ˜¯è°ƒç”¨__call__å‡½æ•°)\n",
    "print(type(img_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ba80909-9ded-4c7d-962b-b31407c22b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3137, 0.3137, 0.3137,  ..., 0.3176, 0.3098, 0.2980],\n",
      "         [0.3176, 0.3176, 0.3176,  ..., 0.3176, 0.3098, 0.2980],\n",
      "         [0.3216, 0.3216, 0.3216,  ..., 0.3137, 0.3098, 0.3020],\n",
      "         ...,\n",
      "         [0.3412, 0.3412, 0.3373,  ..., 0.1725, 0.3725, 0.3529],\n",
      "         [0.3412, 0.3412, 0.3373,  ..., 0.3294, 0.3529, 0.3294],\n",
      "         [0.3412, 0.3412, 0.3373,  ..., 0.3098, 0.3059, 0.3294]],\n",
      "\n",
      "        [[0.5922, 0.5922, 0.5922,  ..., 0.5961, 0.5882, 0.5765],\n",
      "         [0.5961, 0.5961, 0.5961,  ..., 0.5961, 0.5882, 0.5765],\n",
      "         [0.6000, 0.6000, 0.6000,  ..., 0.5922, 0.5882, 0.5804],\n",
      "         ...,\n",
      "         [0.6275, 0.6275, 0.6235,  ..., 0.3608, 0.6196, 0.6157],\n",
      "         [0.6275, 0.6275, 0.6235,  ..., 0.5765, 0.6275, 0.5961],\n",
      "         [0.6275, 0.6275, 0.6235,  ..., 0.6275, 0.6235, 0.6314]],\n",
      "\n",
      "        [[0.9137, 0.9137, 0.9137,  ..., 0.9176, 0.9098, 0.8980],\n",
      "         [0.9176, 0.9176, 0.9176,  ..., 0.9176, 0.9098, 0.8980],\n",
      "         [0.9216, 0.9216, 0.9216,  ..., 0.9137, 0.9098, 0.9020],\n",
      "         ...,\n",
      "         [0.9294, 0.9294, 0.9255,  ..., 0.5529, 0.9216, 0.8941],\n",
      "         [0.9294, 0.9294, 0.9255,  ..., 0.8863, 1.0000, 0.9137],\n",
      "         [0.9294, 0.9294, 0.9255,  ..., 0.9490, 0.9804, 0.9137]]])\n"
     ]
    }
   ],
   "source": [
    "print(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afa52d6f-f19a-4cce-9ac0-e3fa97b39bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 512, 768])\n"
     ]
    }
   ],
   "source": [
    "print(img_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f1dbe4-b209-4ee9-b6f9-90858d61ffeb",
   "metadata": {},
   "source": [
    "è¯´æ˜ï¼šç»´åº¦0 æ·±åº¦ï¼ˆé€šé“æ•°ï¼‰ï¼›ç»´åº¦1 è¡Œæ•°ï¼ˆé«˜ï¼‰ï¼Œç»´åº¦2 åˆ—æ•°ï¼ˆå®½ï¼‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
